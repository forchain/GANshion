{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Author : Ali Mirzaei\n",
    "# Date : 19/09/2017\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import random\n",
    "import math\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import plot_model \n",
    "from tensorflow.keras.layers import BatchNormalization, Input, Dense, Dropout, Flatten, Activation,Concatenate,LeakyReLU\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend, models\n",
    "#import tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# need to add these for the GPU\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# import the image generator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the parameters for training\n",
    "\n",
    "# batch size and image width to use\n",
    "batch_size=128\n",
    "width=100\n",
    "\n",
    "# all the data directories\n",
    "train_dir='train/';\n",
    "test_dir='test/'\n",
    "valid_dir='valid/';\n",
    "\n",
    "# the number of epochs\n",
    "num_epochs=10\n",
    "\n",
    "# creating an image generator that will feed the data from\n",
    "# each of the directories\n",
    "\n",
    "# we use scaling transformation in this generator\n",
    "generator=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# we specify the size of the input and batch size\n",
    "# size of the input is necessary because the image\n",
    "# needs to be rescaled for the neural network\n",
    "\n",
    "train_data=generator.flow_from_directory(train_dir, target_size=(width,width),batch_size=batch_size)\n",
    "valid_data=generator.flow_from_directory(valid_dir, target_size=(width,width),batch_size=batch_size)\n",
    "test_data=generator.flow_from_directory(test_dir, target_size=(width,width),batch_size=batch_size)\n",
    "\n",
    "# the number of steps per epoch is samples/batch size\n",
    "# we need to use these numbers later\n",
    "\n",
    "train_steps_per_epoch=math.ceil(train_data.samples/batch_size)\n",
    "valid_steps_per_epoch=math.ceil(valid_data.samples/batch_size)\n",
    "test_steps_per_epoch=math.ceil(test_data.samples/batch_size)\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    \"\"\"Convert from color image (RGB) to grayscale.\n",
    "       Source: opencv.org\n",
    "       grayscale = 0.299*red + 0.587*green + 0.114*blue\n",
    "    Argument:\n",
    "        rgb (tensor): rgb image\n",
    "    Return:\n",
    "        (tensor): grayscale image\n",
    "    \"\"\"\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "x_train, y_train = train_data.next()\n",
    "x_test, y_test = valid_data.next()\n",
    "x_train.shape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def show_image(x):\n",
    "    plt.imshow(np.clip(x, 0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x_train[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = RandomNormal(mean=0.0, stddev=0.01, seed=None)\n",
    "from keras import backend as K\n",
    "\n",
    "epochs=5000\n",
    "\n",
    "img_rows = width\n",
    "img_cols = width\n",
    "channels = 3\n",
    "\n",
    "# network parameters\n",
    "input_shape = (img_rows, img_cols, channels)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "filters = 16\n",
    "latent_dim = 256\n",
    "# encoder/decoder number of CNN layers and filters per layer\n",
    "layer_filters = [32]\n",
    "\n",
    "\n",
    "class AAN():\n",
    "    def __init__(self, img_shape=input_shape, encoded_dim=latent_dim):\n",
    "        \n",
    "        self.encoded_dim = encoded_dim\n",
    "        self.optimizer_reconst = Adam(0.01)\n",
    "        self.optimizer_discriminator = Adam(0.01)\n",
    "        self._initAndCompileFullModel(img_shape, encoded_dim)\n",
    "\n",
    "    def _genEncoderModel(self, img_shape, encoded_dim):\n",
    "        \"\"\" Build Encoder Model Based on Paper Configuration\n",
    "        Args:\n",
    "            img_shape (tuple) : shape of input image\n",
    "            encoded_dim (int) : number of latent variables\n",
    "        Return:\n",
    "            A sequential keras model\n",
    "        \"\"\"\n",
    "        \n",
    "        input_shape = img_shape\n",
    "        latent_dim = encoded_dim\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=input_shape, name='encoder_input'))\n",
    "        model.add(Conv2D(32, (5,5), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(Conv2D(64, (5,5), strides=(2,2), activation=\"relu\", padding=\"same\"))\n",
    "        model.add(Conv2D(128, (5,5), strides=(2,2), activation=\"relu\", padding=\"same\"))\n",
    "        \n",
    "        self.shape = model.shape.as_list()\n",
    "        print(self.shape)\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(latent_dim, activation=\"linear\", name='latent_vector'))\n",
    "        encoder = model\n",
    "        encoder.summary()\n",
    "        \n",
    "        return encoder\n",
    "\n",
    "    def _getDecoderModel(self, encoded_dim, img_shape):\n",
    "        \"\"\" Build Decoder Model Based on Paper Configuration\n",
    "        Args:\n",
    "            encoded_dim (int) : number of latent variables\n",
    "            img_shape (tuple) : shape of target images\n",
    "        Return:\n",
    "            A sequential keras model\n",
    "        \"\"\"\n",
    "        \n",
    "        latent_dim = encoded_dim\n",
    "        shape = self.shape\n",
    "        \n",
    "        # build the decoder model\n",
    "        latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "        x = Dense(shape[1]*shape[2]*shape[3], kernel_initializer=initializer,\n",
    "                          bias_initializer=initializer)(latent_inputs)\n",
    "        x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "        model = ke.models.Sequential()\n",
    "        model.add(Input(shape=(latent_dim,), name='decoder_input'))\n",
    "        model.add(Dense(6272))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(Conv2D(64, (5,5), activation=\"relu\", padding=\"same\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(32, (5,5), activation=\"relu\", padding=\"same\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(3, (5,5), activation=\"sigmoid\", padding=\"same\"))\n",
    "\n",
    "\n",
    "        # instantiate decoder model\n",
    "        decoder = model\n",
    "        decoder.summary()\n",
    "        return decoder  \n",
    "\n",
    "    def _getDescriminator(self, encoded_dim):\n",
    "        \"\"\" Build Descriminator Model Based on Paper Configuration\n",
    "        Args:\n",
    "            encoded_dim (int) : number of latent variables\n",
    "        Return:\n",
    "            A sequential keras model\n",
    "        \"\"\"\n",
    "\n",
    "#         input_shape = encoded_dim\n",
    "#         shape = self.shape\n",
    "\n",
    "#         # build the decoder model\n",
    "#         latent_inputs = Input(shape=(latent_dim,), name='discriminator_input')\n",
    "#         x = Dense(shape[1]*shape[2]*shape[3], kernel_initializer=initializer,\n",
    "#                           bias_initializer=initializer)(latent_inputs)\n",
    "#         x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "#         # Stack of BN-ReLU-Transposed Conv2D-UpSampling blocks\n",
    "#         for filters in layer_filters[::-1]:\n",
    "#             #x = BatchNormalization()(x)\n",
    "#             x = Activation('relu')(x)\n",
    "#             x = Conv2DTranspose(filters=filters,\n",
    "#                                 kernel_size=kernel_size,\n",
    "#                                 padding='same', kernel_initializer=initializer,\n",
    "#                           bias_initializer=initializer)(x)\n",
    "#             x = UpSampling2D()(x)\n",
    "\n",
    "#         x = Flatten()(x)\n",
    "#         outputs = Dense(1, name='discriminator_output', activation='sigmoid', \n",
    "#                         kernel_initializer=initializer, bias_initializer=initializer)(x)\n",
    "\n",
    "#         # instantiate discriminator model\n",
    "#         discriminator = Model(latent_inputs, outputs, name='discriminator')\n",
    "#         discriminator.summary()\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation=\"relu\", input_shape=(2,)))\n",
    "        model.add(Dense(32, activation=\"relu\"))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        \n",
    "        return discriminator  \n",
    "\n",
    "    def _initAndCompileFullModel(self, img_shape, encoded_dim):\n",
    "        self.encoder = self._genEncoderModel(img_shape, encoded_dim)\n",
    "        self.decoder = self._getDecoderModel(encoded_dim, img_shape)\n",
    "        self.discriminator = self._getDescriminator(encoded_dim)\n",
    "        img = Input(shape=img_shape)\n",
    "        encoded_repr = self.encoder(img)\n",
    "        gen_img = self.decoder(encoded_repr)\n",
    "        self.autoencoder = Model(img, gen_img)\n",
    "        valid = self.discriminator(encoded_repr)\n",
    "        self.encoder_discriminator = Model(img, valid)\n",
    "        self.discriminator.compile(optimizer=self.optimizer_discriminator,\n",
    "                                   loss='binary_crossentropy',\n",
    "                                   metrics=['accuracy'])\n",
    "        self.autoencoder.compile(optimizer=self.optimizer_reconst,\n",
    "                                 loss ='mse')\n",
    "        for layer in self.discriminator.layers:\n",
    "            layer.trainable = False\n",
    "        self.encoder_discriminator.compile(optimizer=self.optimizer_discriminator,\n",
    "                                           loss='binary_crossentropy',\n",
    "                                           metrics=['accuracy'])\n",
    "    def imagegrid(self, epochnumber):\n",
    "        fig = plt.figure(figsize=[width, width])\n",
    "        images = self.generateImages(5)\n",
    "        for index,img in enumerate(images):\n",
    "            img = img.reshape((width,width,3))\n",
    "            ax = fig.add_subplot(10, 10, index+1)\n",
    "            ax.set_axis_off()\n",
    "            ax.imshow(img)\n",
    "        fig.savefig(\"images/\"+str(epochnumber)+\".png\")\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "    def generateImages(self, n=20):\n",
    "        latents = 5*np.random.normal(size=(n, self.encoded_dim))\n",
    "        imgs = self.decoder.predict(latents)\n",
    "        return imgs\n",
    "\n",
    "    def train(self, x_train, batch_size=batch_size, epochs=epochs, save_interval=10):\n",
    "        half_batch = int(batch_size / 2)\n",
    "        for epoch in range(epochs):\n",
    "            #---------------Train Discriminator -------------\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, x_train.shape[0], half_batch)\n",
    "            imgs = x_train[idx]\n",
    "            # Generate a half batch of new images\n",
    "            latent_fake = self.encoder.predict(imgs)\n",
    "            #gen_imgs = self.decoder.predict(latent_fake)\n",
    "            latent_real = 5*np.random.normal(size=(half_batch, self.encoded_dim))\n",
    "            valid = np.ones((half_batch, 1))\n",
    "            fake = np.zeros((half_batch, 1))\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(latent_real, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(latent_fake, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            imgs = x_train[idx]\n",
    "            # Generator wants the discriminator to label the generated representations as valid\n",
    "            valid_y = np.ones((batch_size, 1))\n",
    "\n",
    "            # Train the autoencode reconstruction\n",
    "            g_loss_reconstruction = self.autoencoder.train_on_batch(imgs, imgs)\n",
    "\n",
    "            # Train generator\n",
    "            g_logg_similarity = self.encoder_discriminator.train_on_batch(imgs, valid_y)\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc: %.2f%%] [G acc: %f, mse: %f]\" % (epoch, d_loss[0], 100*d_loss[1],\n",
    "                   g_logg_similarity[1], g_loss_reconstruction))\n",
    "            if(epoch % save_interval == 0):\n",
    "                self.imagegrid(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-peninsula",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = AAN()\n",
    "ann.train(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[width, width])\n",
    "images = ann.generateImages()\n",
    "for index,img in enumerate(images):\n",
    "            img = img.reshape((width, width,3))\n",
    "            ax = fig.add_subplot(10, 10, index+1)\n",
    "            ax.set_axis_off()\n",
    "            ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def approximateLogLiklihood(x_generated, x_test, searchSpace = np.logspace(-4, 0, 5)):\n",
    "    x_generated = np.array(x_generated).reshape((len(x_generated),-1))\n",
    "    x_test = np.array(x_test).reshape((len(x_test),-1))\n",
    "    # use grid search cross-validation to optimize the bandwidth\n",
    "    print (\"new\")\n",
    "    params = {'bandwidth': searchSpace}\n",
    "    grid = GridSearchCV(KernelDensity(), params, n_jobs=4)\n",
    "    grid.fit(x_generated)\n",
    "    print(grid.best_params_)\n",
    "    kde = grid.best_estimator_\n",
    "    scores = kde.score_samples(x_test)\n",
    "    return np.sum(scores)/len(scores)\n",
    "\n",
    "def findNearest(x_train, x_test):\n",
    "    diff  = np.square(x_train-x_test)\n",
    "    mse = [np.sum(x) for x in diff]\n",
    "    return x_train[np.argmin(mse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-leave",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = ann.generateImages()\n",
    "L= approximateLogLiklihood(generated, x_test)\n",
    "print (\"Log Likelihood\")\n",
    "print (L)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
