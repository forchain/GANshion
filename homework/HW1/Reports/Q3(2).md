# COE59410- Generative Deep Learning

## Homework 1

> Imran A. Zualkernan

The purpose of this homework is to learn how to use the GPU machines to run large models. In addition, build familiarity with the Keras framework and the associated tools.

## Deliverables

**You need to upload the following on ilearn (2 items)**

1. The Jupyter notebook in its original format.

2. A PDF of the Jupyter notebook for grading.

*Please do not upload a zipped file.* Upload each file separately. Each question is worth 25 points.

* Q1. Load and run the large_scale_processing v1.1 Jupyter notebook on the GPU machine and show how you can use tensorboard to monitor the runs remotely on your local machine.

* Q2. Modify the model in large_scale_processing v1.1 so that rather than a CNN, the model is a fully connected feedforward neural network. Fine tune the model to show your best results. Report and discuss all the results that are necessary to determine the goodness of your best model.

> Hint: Use the Reshape Layer in Keras.

* Q3. Use the following two call-backs on your best fully connected model and determine if you are able to improve the results. Clearly explain why or why not.
    1. LearningRateScheduler
    2. ReduceLROnPlateau

* Q4. Use the Keras Hypertune and Random optimizers (https://keras-team.github.io/keras-tuner/) to determine if you can improve the model by varying the number of layers, neurons in each layer and the learning rate.

    1. Plot the precision vs. recall of the best 20 models in one figure.
    2. Show a complete evaluation of the top two models.

## Group 2
* Eman ,
* Huangjin Zhou, b00080932
* Mueez ,


```python
# Useful links 
# https://www.hostinger.com/tutorials/ssh/basic-ssh-commands
```


```python
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
```

    [name: "/device:CPU:0"
    device_type: "CPU"
    memory_limit: 268435456
    locality {
    }
    incarnation: 7878443089637920960
    , name: "/device:GPU:0"
    device_type: "GPU"
    memory_limit: 7491026944
    locality {
      bus_id: 1
      links {
      }
    }
    incarnation: 7592727953676909350
    physical_device_desc: "device: 0, name: Quadro RTX 4000, pci bus id: 0000:01:00.0, compute capability: 7.5"
    ]



```python
import tensorflow as tf
# print(tf.config.list_physical_devices('GPU'))
tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.list_physical_devices(device_type=None)
tf.test.is_gpu_available()
print(tf.test.is_built_with_cuda())
```

    WARNING:tensorflow:From <ipython-input-3-ca90116ab0f5>:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
    Instructions for updating:
    Use `tf.config.list_physical_devices('GPU')` instead.
    True



```python
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from IPython.display import Image, display
import random
import math
import keras
from keras.preprocessing.text import Tokenizer
from keras.models import Model, Sequential
from keras.utils import plot_model 
from keras.layers import Reshape, Input, Dense, Dropout, Flatten, Activation,Concatenate
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D
from keras.optimizers import Adam
from keras import backend, models
#import tensorflow_addons as tfa
import tensorflow as tf
print(tf.__version__)

# need to add these for the GPU
config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.compat.v1.Session(config=config)
```

    2.4.1



```python
# import the image generator
from tensorflow.keras.preprocessing.image import ImageDataGenerator
```


```python
#Setting the parameters for training

# batch size and image width to use
batch_size=128
width=100

# all the data directories
train_dir='train/'
test_dir='test/'
valid_dir='valid/'

# the number of epochs
num_epochs=10

# creating an image generator that will feed the data from
# each of the directories

# we use scaling transformation in this generator
generator=ImageDataGenerator(rescale=1./255)

# we specify the size of the input and batch size
# size of the input is necessary because the image
# needs to be rescaled for the neural network

train_data=generator.flow_from_directory(train_dir, target_size=(width,width),batch_size=batch_size)
valid_data=generator.flow_from_directory(valid_dir, target_size=(width,width),batch_size=batch_size)
test_data=generator.flow_from_directory(test_dir, target_size=(width,width),batch_size=batch_size)

# the number of steps per epoch is samples/batch size
# we need to use these numbers later

train_steps_per_epoch=math.ceil(train_data.samples/batch_size)
valid_steps_per_epoch=math.ceil(valid_data.samples/batch_size)
test_steps_per_epoch=math.ceil(test_data.samples/batch_size)
print(train_steps_per_epoch)
print(valid_steps_per_epoch)
print(test_steps_per_epoch)
```

    Found 35215 images belonging to 250 classes.
    Found 1250 images belonging to 250 classes.
    Found 1250 images belonging to 250 classes.
    276
    10
    10


> Q1. Load and run the large_scale_processing v1.1 Jupyter notebook on the GPU machine and
show how you can use tensorboard to monitor the runs remotely on your local machine.


```shell
$ jupyter notebook --port 9999 --NotebookApp.allow_remote_access=True
$ tensorboard --logdir logs/fit --port=8888
```
> Scalars
![Scalars](images/scalar.jpg)
![Graph](images/graph.jpg)
![Time Series](images/timeseries.jpg)


```python
Q1 = False
if Q1:
    # the actual model should go here
    model = Sequential()
    model.add(Conv2D(32, (3, 3), input_shape=(width, width, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Dropout(0.5))

    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(256, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Flatten())
    model.add(Dense(1024, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(250, activation='softmax'))
    model.summary()
```


```python
if Q1:
    # Compile the model
    model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

    # see if the model is good.
    print(model)
```


```python
if Q1:
    print(valid_steps_per_epoch)
    num_epochs = 20
    # fit model and add tensor board callbacks
    from tensorflow.keras.callbacks import TensorBoard
    tensorboard = TensorBoard(log_dir='logs/fit')
    history=model.fit(train_data,
                  steps_per_epoch =train_steps_per_epoch,
                  validation_data=valid_data,
                  epochs=num_epochs,
                  validation_steps=valid_steps_per_epoch, callbacks=[tensorboard])
```



Q2. Modify the model in large_scale_processing v1.1 so that rather than a CNN,
the model is a fully connected feedforward neural network.
Fine tune the model to show your best results.
Report and discuss all the results that are necessary to determine the goodness of your best model.


> Hint: Use the Reshape Layer in Keras.

### adjust hidden units
we fix only 1 hidden layer and to see which unit number is best for us

```python
hidden_units = 128*1
```
```shell
 loss: 5.5032 - accuracy: 0.0087 - val_loss: 5.5339 - val_accuracy: 0.0040
```

```python
hidden_units = 128*2
```
```shell
 loss: 5.5122 - accuracy: 0.0076 - val_loss: 5.5246 - val_accuracy: 0.0040
```

```python
hidden_units = 128*4
```
```shell
 loss: 5.3341 - accuracy: 0.0126 - val_loss: 5.3179 - val_accuracy: 0.0120
```
```python
hidden_units = 128*8
```
```shell
 loss: 4.8888 - accuracy: 0.0391 - val_loss: 4.7778 - val_accuracy: 0.0336
```
```python
hidden_units = 128*16
```
```shell
 loss: 4.6924 - accuracy: 0.0555 - val_loss: 4.6376 - val_accuracy: 0.0520
```

```python
hidden_units = 128*32
```
```shell
 loss: 4.9463 - accuracy: 0.0294 - val_loss: 4.8971 - val_accuracy: 0.0312
```

from the report, we could make a conclusion
1. the val_accuracy on 128*32=4096 units is lower than on 128*16=2048, that is 0.0312 < 0.0312, we stop try more units.
2. the accuracy increased ratio from 1024 units to 2048 , which is 0.0520/0.0336=1.54, is less than that from 512 units to 1024,
which is 0.0336/0.0120=2.8. Therefore, if we have enough computation resources, we prefer 2048, otherwise 1024.

### adjust hidden layers

we fixed units number to 1024 or 2048, and then increase the layer number to see how many
layers work best

```python
hidden_units = 128*8

model.add(Dense(hidden_units, activation='relu'))
model.add(Dense(hidden_units, activation='relu'))
...
```
```shell
loss: 4.2517 - accuracy: 0.0861 - val_loss: 4.1615 - val_accuracy: 0.0952
```


```python
hidden_units = 128*16
model.add(Dense(hidden_units, activation='relu'))
model.add(Dense(hidden_units, activation='relu'))
...
```
```shell
loss: 5.5034 - accuracy: 0.0085 - val_loss: 5.5354 - val_accuracy: 0.0040
```
stop trying 128*16 units for one layer since accuracy doesn't increase

```python
hidden_units = 128*8
model.add(Dense(hidden_units, activation='relu'))
model.add(Dense(hidden_units, activation='relu'))
model.add(Dense(hidden_units, activation='relu'))
```
```shell
 loss: 3.1438 - accuracy: 0.2647 - val_loss: 3.4928 - val_accuracy: 0.2296
```

```python
hidden_units = 128*8
model.add(Dense(hidden_units, activation='relu'))
model.add(Dense(hidden_units, activation='relu'))
model.add(Dense(hidden_units, activation='relu'))
model.add(Dense(hidden_units, activation='relu'))
```
```shell
 loss: 3.2843 - accuracy: 0.2326 - val_loss: 3.5376 - val_accuracy: 0.2080
```

##### conclusion
1. units of 2048 for single layer is too much, because the accuracy of two dense layer goes
lower than that of single layer, which stops at 0.0040
2. 3 dense layers are best match with 1024 units number, since the accuracy of 4 layers
goes lower than that of 3 layers, which is 0.2080 < 0.2296

### try more epochs

we set epoch number to 10 just to find hyperparameters quickly, however, this epoch is
not enough since the accuracy keeps going up, we will enlarge this number and observe
the accuracy until it converges

```python
num_epochs = 10*10

hidden_units = 128*8

model.add(Dense(hidden_units, activation='relu'))
model.add(Dense(hidden_units, activation='relu'))
model.add(Dense(hidden_units, activation='relu'))
```
```shell
Epoch 20/100
loss: 1.3170 - accuracy: 0.6387 - val_loss: 4.6068 - val_accuracy: 0.2816
...
Epoch 30/100
loss: 0.4543 - accuracy: 0.8656 - val_loss: 7.4723 - val_accuracy: 0.2720
```

conclusion:
the accuracy reaches to top of 0.2816 at epoch 20, so we assume 20 epochs is enough

we sum up, hidden units, layer number, epoch number, and the final code is as below:


```python
Q2 = False
Q3 = True
if Q2 or Q3:
    # since we just try to find the best parameters, so we just try 10 epochs
    num_epochs = 20

    # try different units

    num_labels = train_data.num_classes

    hidden_units = 1024
    model = Sequential()
    model.add(Reshape((-1,), input_shape=(width, width, 3)))
    model.add(Dense(hidden_units, activation='relu'))
    model.add(Dense(hidden_units, activation='relu'))
    model.add(Dense(hidden_units, activation='relu'))
    model.add(Dense(num_labels, activation='softmax'))
    model.summary()

    # Compile the model
    model.compile(loss='categorical_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
if Q2:
    history=model.fit(train_data,
                      steps_per_epoch =train_steps_per_epoch,
                      validation_data=valid_data,
                      epochs=num_epochs,
                      validation_steps=valid_steps_per_epoch)
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    reshape (Reshape)            (None, 30000)             0         
    _________________________________________________________________
    dense (Dense)                (None, 1024)              30721024  
    _________________________________________________________________
    dense_1 (Dense)              (None, 1024)              1049600   
    _________________________________________________________________
    dense_2 (Dense)              (None, 1024)              1049600   
    _________________________________________________________________
    dense_3 (Dense)              (None, 250)               256250    
    =================================================================
    Total params: 33,076,474
    Trainable params: 33,076,474
    Non-trainable params: 0
    _________________________________________________________________



```python
#%%

from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau
num_epochs = 10*10

# dynamic
def lr_schedule(epoch):
    """Learning rate scheduler - called every epoch"""
    
    # starting point
    lr = 1e-4
    # dynamic optimization, abandoned due to bad performance
    # if epoch > 10:
    #     lr = 1e-5

    return lr

lr_scheduler = LearningRateScheduler(lr_schedule)

lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),
                               cooldown=0,
                               patience=5,
                               verbose=1,
                               min_lr=1e-6)

callbacks = [lr_reducer, lr_scheduler]
#callbacks = [ lr_scheduler]
history=model.fit(train_data,
                  steps_per_epoch =train_steps_per_epoch,
                  validation_data=valid_data,
                  epochs=num_epochs,
                  validation_steps=valid_steps_per_epoch, callbacks=callbacks)
exit()
```

    Epoch 1/100
    276/276 [==============================] - 27s 99ms/step - loss: 5.4927 - accuracy: 0.0116 - val_loss: 4.9565 - val_accuracy: 0.0368
    Epoch 2/100
    276/276 [==============================] - 27s 97ms/step - loss: 4.8362 - accuracy: 0.0556 - val_loss: 4.4972 - val_accuracy: 0.0704
    Epoch 3/100
    276/276 [==============================] - 27s 97ms/step - loss: 4.4281 - accuracy: 0.0986 - val_loss: 4.1068 - val_accuracy: 0.1368
    Epoch 4/100
    276/276 [==============================] - 27s 97ms/step - loss: 4.1225 - accuracy: 0.1407 - val_loss: 3.8501 - val_accuracy: 0.1640
    Epoch 5/100
    276/276 [==============================] - 27s 98ms/step - loss: 3.8882 - accuracy: 0.1735 - val_loss: 3.7192 - val_accuracy: 0.1816
    Epoch 6/100
    276/276 [==============================] - 27s 98ms/step - loss: 3.6921 - accuracy: 0.2079 - val_loss: 3.5485 - val_accuracy: 0.2144
    Epoch 7/100
    276/276 [==============================] - 27s 98ms/step - loss: 3.5504 - accuracy: 0.2283 - val_loss: 3.4841 - val_accuracy: 0.2272
    Epoch 8/100
    276/276 [==============================] - 27s 98ms/step - loss: 3.3834 - accuracy: 0.2594 - val_loss: 3.3238 - val_accuracy: 0.2488
    Epoch 9/100
    276/276 [==============================] - 27s 98ms/step - loss: 3.2288 - accuracy: 0.2828 - val_loss: 3.3805 - val_accuracy: 0.2424
    Epoch 10/100
    276/276 [==============================] - 27s 98ms/step - loss: 3.1058 - accuracy: 0.3076 - val_loss: 3.3119 - val_accuracy: 0.2472
    Epoch 11/100
    276/276 [==============================] - 27s 98ms/step - loss: 2.9721 - accuracy: 0.3311 - val_loss: 3.1605 - val_accuracy: 0.2880
    Epoch 12/100
    276/276 [==============================] - 27s 98ms/step - loss: 2.8712 - accuracy: 0.3494 - val_loss: 3.0899 - val_accuracy: 0.2944
    Epoch 13/100
    276/276 [==============================] - 27s 98ms/step - loss: 2.7547 - accuracy: 0.3699 - val_loss: 3.1314 - val_accuracy: 0.2848
    Epoch 14/100
    276/276 [==============================] - 27s 98ms/step - loss: 2.6616 - accuracy: 0.3887 - val_loss: 3.0046 - val_accuracy: 0.3024
    Epoch 15/100
    276/276 [==============================] - 27s 98ms/step - loss: 2.5341 - accuracy: 0.4166 - val_loss: 3.0169 - val_accuracy: 0.3048
    Epoch 16/100
    276/276 [==============================] - 27s 99ms/step - loss: 2.4191 - accuracy: 0.4379 - val_loss: 3.0417 - val_accuracy: 0.3160
    Epoch 17/100
    276/276 [==============================] - 27s 98ms/step - loss: 2.3282 - accuracy: 0.4560 - val_loss: 2.9795 - val_accuracy: 0.3208
    Epoch 18/100
    276/276 [==============================] - 27s 98ms/step - loss: 2.2283 - accuracy: 0.4795 - val_loss: 2.9377 - val_accuracy: 0.3344
    Epoch 19/100
    276/276 [==============================] - 27s 98ms/step - loss: 2.1058 - accuracy: 0.5055 - val_loss: 3.0007 - val_accuracy: 0.3264
    Epoch 20/100
    276/276 [==============================] - 27s 98ms/step - loss: 2.0414 - accuracy: 0.5147 - val_loss: 2.9402 - val_accuracy: 0.3432
    Epoch 21/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.9319 - accuracy: 0.5408 - val_loss: 2.9627 - val_accuracy: 0.3440
    Epoch 22/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.8510 - accuracy: 0.5583 - val_loss: 2.9558 - val_accuracy: 0.3488
    Epoch 23/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.7744 - accuracy: 0.5757 - val_loss: 3.0351 - val_accuracy: 0.3296
    
    Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 24/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.6634 - accuracy: 0.6005 - val_loss: 2.9863 - val_accuracy: 0.3544
    Epoch 25/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.5713 - accuracy: 0.6242 - val_loss: 3.0444 - val_accuracy: 0.3480
    Epoch 26/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.4929 - accuracy: 0.6419 - val_loss: 3.0229 - val_accuracy: 0.3504
    Epoch 27/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.3935 - accuracy: 0.6665 - val_loss: 3.1046 - val_accuracy: 0.3336
    Epoch 28/100
    276/276 [==============================] - 27s 99ms/step - loss: 1.3415 - accuracy: 0.6763 - val_loss: 3.1729 - val_accuracy: 0.3376
    
    Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 29/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.2790 - accuracy: 0.6932 - val_loss: 3.1088 - val_accuracy: 0.3552
    Epoch 30/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.2030 - accuracy: 0.7102 - val_loss: 3.1645 - val_accuracy: 0.3480
    Epoch 31/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.0954 - accuracy: 0.7383 - val_loss: 3.1554 - val_accuracy: 0.3544
    Epoch 32/100
    276/276 [==============================] - 27s 98ms/step - loss: 1.0361 - accuracy: 0.7530 - val_loss: 3.2358 - val_accuracy: 0.3512
    Epoch 33/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.9639 - accuracy: 0.7746 - val_loss: 3.3438 - val_accuracy: 0.3464
    
    Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 34/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.8956 - accuracy: 0.7877 - val_loss: 3.3004 - val_accuracy: 0.3600
    Epoch 35/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.8473 - accuracy: 0.8041 - val_loss: 3.3274 - val_accuracy: 0.3512
    Epoch 36/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.7751 - accuracy: 0.8213 - val_loss: 3.4022 - val_accuracy: 0.3528
    Epoch 37/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.7228 - accuracy: 0.8376 - val_loss: 3.6169 - val_accuracy: 0.3384
    Epoch 38/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.6940 - accuracy: 0.8396 - val_loss: 3.4474 - val_accuracy: 0.3648
    
    Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 39/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.6257 - accuracy: 0.8636 - val_loss: 3.5158 - val_accuracy: 0.3600
    Epoch 40/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.5534 - accuracy: 0.8804 - val_loss: 3.5295 - val_accuracy: 0.3480
    Epoch 41/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.5124 - accuracy: 0.8913 - val_loss: 3.6006 - val_accuracy: 0.3544
    Epoch 42/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.4748 - accuracy: 0.9001 - val_loss: 3.6802 - val_accuracy: 0.3704
    Epoch 43/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.4293 - accuracy: 0.9119 - val_loss: 3.8230 - val_accuracy: 0.3608
    
    Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 44/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.3919 - accuracy: 0.9207 - val_loss: 3.7613 - val_accuracy: 0.3504
    Epoch 45/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.3625 - accuracy: 0.9292 - val_loss: 3.8496 - val_accuracy: 0.3504
    Epoch 46/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.3173 - accuracy: 0.9434 - val_loss: 3.8497 - val_accuracy: 0.3632
    Epoch 47/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.2878 - accuracy: 0.9482 - val_loss: 3.9786 - val_accuracy: 0.3576
    Epoch 48/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.2515 - accuracy: 0.9586 - val_loss: 4.0499 - val_accuracy: 0.3456
    
    Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 49/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.2446 - accuracy: 0.9570 - val_loss: 4.1174 - val_accuracy: 0.3544
    Epoch 50/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.2097 - accuracy: 0.9670 - val_loss: 4.2234 - val_accuracy: 0.3608
    Epoch 51/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.1890 - accuracy: 0.9714 - val_loss: 4.2084 - val_accuracy: 0.3552
    Epoch 52/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.1875 - accuracy: 0.9706 - val_loss: 4.2955 - val_accuracy: 0.3488
    Epoch 53/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.1511 - accuracy: 0.9799 - val_loss: 4.3686 - val_accuracy: 0.3600
    
    Epoch 00053: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 54/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.1359 - accuracy: 0.9832 - val_loss: 4.4241 - val_accuracy: 0.3736
    Epoch 55/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.1172 - accuracy: 0.9864 - val_loss: 4.4373 - val_accuracy: 0.3584
    Epoch 56/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.1210 - accuracy: 0.9844 - val_loss: 4.5734 - val_accuracy: 0.3616
    Epoch 57/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.1250 - accuracy: 0.9816 - val_loss: 4.5977 - val_accuracy: 0.3576
    Epoch 58/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0980 - accuracy: 0.9883 - val_loss: 4.8052 - val_accuracy: 0.3592
    
    Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 59/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.1289 - accuracy: 0.9781 - val_loss: 4.6786 - val_accuracy: 0.3776
    Epoch 60/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0672 - accuracy: 0.9940 - val_loss: 4.7880 - val_accuracy: 0.3760
    Epoch 61/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0691 - accuracy: 0.9929 - val_loss: 4.8937 - val_accuracy: 0.3488
    Epoch 62/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0962 - accuracy: 0.9838 - val_loss: 4.9163 - val_accuracy: 0.3432
    Epoch 63/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.1206 - accuracy: 0.9774 - val_loss: 5.0038 - val_accuracy: 0.3552
    
    Epoch 00063: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 64/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.1108 - accuracy: 0.9792 - val_loss: 4.8813 - val_accuracy: 0.3760
    Epoch 65/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0363 - accuracy: 0.9976 - val_loss: 4.9472 - val_accuracy: 0.3680
    Epoch 66/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0283 - accuracy: 0.9989 - val_loss: 4.9855 - val_accuracy: 0.3800
    Epoch 67/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0241 - accuracy: 0.9989 - val_loss: 5.0505 - val_accuracy: 0.3776
    Epoch 68/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0229 - accuracy: 0.9978 - val_loss: 5.2943 - val_accuracy: 0.3216
    
    Epoch 00068: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 69/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.3415 - accuracy: 0.8979 - val_loss: 5.0428 - val_accuracy: 0.3608
    Epoch 70/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0405 - accuracy: 0.9961 - val_loss: 5.1092 - val_accuracy: 0.3728
    Epoch 71/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0140 - accuracy: 0.9999 - val_loss: 5.1399 - val_accuracy: 0.3800
    Epoch 72/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0115 - accuracy: 0.9997 - val_loss: 5.2219 - val_accuracy: 0.3744
    Epoch 73/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0093 - accuracy: 0.9999 - val_loss: 5.3011 - val_accuracy: 0.3808
    
    Epoch 00073: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 74/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0148 - accuracy: 0.9990 - val_loss: 5.8864 - val_accuracy: 0.3016
    Epoch 75/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.3332 - accuracy: 0.9026 - val_loss: 5.2415 - val_accuracy: 0.3664
    Epoch 76/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0471 - accuracy: 0.9934 - val_loss: 5.1068 - val_accuracy: 0.3816
    Epoch 77/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0095 - accuracy: 0.9999 - val_loss: 5.2042 - val_accuracy: 0.3792
    Epoch 78/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0085 - accuracy: 0.9996 - val_loss: 5.2753 - val_accuracy: 0.3800
    
    Epoch 00078: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 79/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0067 - accuracy: 0.9999 - val_loss: 5.3454 - val_accuracy: 0.3816
    Epoch 80/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 5.4283 - val_accuracy: 0.3760
    Epoch 81/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.2467 - accuracy: 0.9291 - val_loss: 5.3073 - val_accuracy: 0.3568
    Epoch 82/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0702 - accuracy: 0.9862 - val_loss: 5.2234 - val_accuracy: 0.3840
    Epoch 83/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0094 - accuracy: 0.9997 - val_loss: 5.3247 - val_accuracy: 0.3776
    
    Epoch 00083: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 84/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 5.4195 - val_accuracy: 0.3832
    Epoch 85/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0055 - accuracy: 0.9999 - val_loss: 5.5080 - val_accuracy: 0.3752
    Epoch 86/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0059 - accuracy: 0.9999 - val_loss: 5.4967 - val_accuracy: 0.3928
    Epoch 87/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0280 - accuracy: 0.9934 - val_loss: 5.6465 - val_accuracy: 0.3216
    Epoch 88/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.2203 - accuracy: 0.9368 - val_loss: 5.3780 - val_accuracy: 0.3568
    
    Epoch 00088: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 89/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0287 - accuracy: 0.9962 - val_loss: 5.4806 - val_accuracy: 0.3760
    Epoch 90/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0078 - accuracy: 0.9999 - val_loss: 5.4613 - val_accuracy: 0.3776
    Epoch 91/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 5.5275 - val_accuracy: 0.3816
    Epoch 92/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 5.5853 - val_accuracy: 0.3856
    Epoch 93/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 5.6559 - val_accuracy: 0.3904
    
    Epoch 00093: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 94/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0799 - accuracy: 0.9781 - val_loss: 5.4677 - val_accuracy: 0.3384
    Epoch 95/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.1137 - accuracy: 0.9715 - val_loss: 5.4460 - val_accuracy: 0.3728
    Epoch 96/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0142 - accuracy: 0.9991 - val_loss: 5.4825 - val_accuracy: 0.3824
    Epoch 97/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 5.5276 - val_accuracy: 0.3856
    Epoch 98/100
    276/276 [==============================] - 27s 99ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 5.7639 - val_accuracy: 0.3736
    
    Epoch 00098: ReduceLROnPlateau reducing learning rate to 3.1622775802825264e-05.
    Epoch 99/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0568 - accuracy: 0.9858 - val_loss: 5.5637 - val_accuracy: 0.3440
    Epoch 100/100
    276/276 [==============================] - 27s 98ms/step - loss: 0.0821 - accuracy: 0.9802 - val_loss: 5.5801 - val_accuracy: 0.3704



```python

from kerastuner.tuners import RandomSearch

def build_model(hp):
    model = Sequential()
    model.add(Reshape((-1,), input_shape=(width, width, 3)))
    model.add(Dense(units=hp.Int('units',
                                        min_value=128,
                                        max_value=1024,
                                        step=128),
                           activation='relu'))
    model.add(Dense(units=hp.Int('units',
                                        min_value=128,
                                        max_value=1024,
                                        step=128),
                           activation='relu'))
    model.add(Dense(units=hp.Int('units',
                                        min_value=128,
                                        max_value=1024,
                                        step=128),
                           activation='relu'))
    model.add(Dense(num_labels, activation='softmax'))
    model.compile(
        optimizer=keras.optimizers.Adam(
            hp.Choice('learning_rate',
                      values=[1e-2, 1e-3, 1e-4])),
        loss='categorical_crossentropy',
        metrics=['accuracy'])
    return model
```


    ---------------------------------------------------------------------------

    ModuleNotFoundError                       Traceback (most recent call last)

    <ipython-input-12-2db584aa9595> in <module>
    ----> 1 from kerastuner.tuners import RandomSearch
          2 
          3 def build_model(hp):
          4     model = Sequential()
          5     model.add(Reshape((-1,), input_shape=(width, width, 3)))


    ModuleNotFoundError: No module named 'kerastuner'



```python
# Compile the model
model.compile(loss='categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy'])
```


```python
# see if the model is good. 
print(model)
```


```python
from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau

def lr_schedule(epoch):
    """Learning rate scheduler - called every epoch"""
    lr = 1e-3
    fold = int(epoch / 10) + 1
    lr /=  fold

    return lr

lr_scheduler = LearningRateScheduler(lr_schedule)

lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),
                               cooldown=0,
                               patience=5,
                               min_lr=0.5e-6)

```


```python
from tensorflow.keras.callbacks import TensorBoard
tensorboard = TensorBoard(log_dir='logs/fit')

print(valid_steps_per_epoch)
num_epochs = 20

callbacks = [lr_reducer, lr_scheduler, tensorboard]
history=model.fit(train_data,
                  steps_per_epoch =train_steps_per_epoch,
                  validation_data=valid_data,
                  epochs=num_epochs,
                  validation_steps=valid_steps_per_epoch, callbacks=callbacks)
```


```python

```


```python
# Compile the model
from keras import metrics

model.compile(loss='categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy',
                        metrics.AUC(name='my_auc'),
                        F1_Score])
```


```python
# https://keras.io/api/callbacks/
# We can use a variety of pre-defined callbacks.
# Experiment with ReduceLROnPlateuau()

import tensorflow_addons as tfa

from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, LearningRateScheduler

# We can also do a modelcheck point 
# https://machinelearningmastery.com/check-point-deep-learning-models-keras/
  
# checkpoint to save the model with best validation accuracy
checkpoint = ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5', 
                             monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

# We can also stop the model early
#https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/
# val_loss
early_stopping_callback = EarlyStopping(monitor='accuracy', mode='min', verbose=1, patience=200)


# initialize TimeStopping callback
# https://www.tensorflow.org/addons/tutorials/time_stopping
# note that it will still run a minimum of 1 epoch
time_stopping_callback = tfa.callbacks.TimeStopping(seconds=600, verbose=1)

# We can also use CVSLogger to log information in a CSV
csvlogger = CSVLogger("logfile.csv",separator=',',append=False)


# ** IMPORTANT ** - please make sure that csvlogger is the last call back
# in the list.

my_callbacks = [time_stopping_callback,early_stopping_callback,checkpoint,csvlogger]

                                  
```


```python
# Fitting the model with call-backs

num_epochs = 1

history=model.fit(train_data,
                  steps_per_epoch =train_steps_per_epoch, 
                  validation_data=valid_data,
                  epochs=num_epochs,
                  validation_steps=valid_steps_per_epoch,
                  callbacks=my_callbacks)

```


```python

```


```python
# Compile the model
from keras import metrics
model.compile(loss='categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy',
                        metrics.AUC(name='auc'),
                        metrics.Precision(name='precision'),
                        metrics.Recall(name='recall')])

# Fitting the model with more metrics

num_epochs = 1

history=model.fit(train_data,
                  steps_per_epoch =train_steps_per_epoch, 
                  validation_data=valid_data,
                  epochs=num_epochs,
                  validation_steps=valid_steps_per_epoch,
                  callbacks=my_callbacks)
```


```python
# Defining custom metrics to record while running
from keras import backend as K

def F1_Score(y_true, y_pred): #taken from old keras source code
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    recall = true_positives / (possible_positives + K.epsilon())
    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())
    return f1_val

def my_metric_fn(y_true, y_pred):
    squared_difference = tf.square(y_true - y_pred)
    return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`
```


```python
# Compile the model
from keras import metrics
model.compile(loss='categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy',
                        metrics.AUC(name='auc'),
                        metrics.Precision(name='precision'),
                        metrics.Recall(name='recall'),
                        F1_Score])

# Fitting the model with more metrics

num_epochs = 1

history=model.fit(train_data,
                  steps_per_epoch =train_steps_per_epoch, 
                  validation_data=valid_data,
                  epochs=num_epochs,
                  validation_steps=valid_steps_per_epoch,
                  callbacks=my_callbacks)
```


```python
# Defining custom call backs

# https://www.tensorflow.org/guide/keras/custom_callback
# https://keras.io/guides/writing_your_own_callbacks/

from keras.callbacks import Callback
import time

class TimingCallback(keras.callbacks.Callback):
    def __init__(self):
        super(TimingCallback, self).__init__()
    def on_batch_begin(self, epoch, logs=None):
        self.starttime=time.time()
    def on_batch_end(self, epoch, logs=None):
        logs['epoch_time'] = (time.time()-self.starttime)
        print('\nepoch_time(sec)=',logs['epoch_time'],'\n')
        
# create an instance of the timingcallback
timing_call = TimingCallback() 

# We can also use other metrics
# https://keras.io/api/metrics/
class PrintBatchCallback(keras.callbacks.Callback):  
    def on_train_batch_end(self, batch, logs=None):
        print("For batch {}, loss is {:7.2f}.".format(batch, logs["loss"]))
        print("For batch {}, accuracy is {:7.2f}.".format(batch, logs["accuracy"]))
        print("For batch {}, AUC is {:7.2f}.".format(batch, logs["auc"]))

print_batch_call = PrintBatchCallback()

# add to the callback list
my_callbacks = [time_stopping_callback,early_stopping_callback,checkpoint,print_batch_call, timing_call, CSVLogger('new.csv', separator=',')]

```


```python
# Compile the model
from keras import metrics
model.compile(loss='categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy',
                        metrics.AUC(name='auc'),
                        metrics.Precision(name='precision'),
                        metrics.Recall(name='recall'),
                        F1_Score])

# Fitting the model with more metrics

num_epochs = 1

history=model.fit(train_data,
                  steps_per_epoch =train_steps_per_epoch, 
                  validation_data=valid_data,
                  epochs=num_epochs,
                  validation_steps=valid_steps_per_epoch,
                  callbacks=my_callbacks)
```


```python
# https://neptune.ai/blog/keras-metrics

# How to save batch level data in a file 

import os
from keras.callbacks import Callback
import numpy as np


class SaveBatchLevelDataCallback(keras.callbacks.Callback):
    def __init__(self, validation_data, save_dir):
        super().__init__()
        self.validation_data = validation_data
        os.makedirs(save_dir, exist_ok=True)
        self.save_dir = save_dir
        self.f = None

    def on_epoch_begin(self, epoch, logs=None):
        # create a file
        self.f= open(os.path.join(self.save_dir, f'epoch_{epoch}.csv'),'w+')
        line = "batch,loss,accuracy,auc\n"
        self.f.write(line)
    
    def on_epoch_end(self, batch, logs=None):
        self.f.close()
        
    def on_train_batch_end(self, batch, logs=None):
        line = "{},{:7.2f},{:7.2f},{:7.2f}\n".format(batch, logs["loss"], logs["accuracy"],logs["auc"])
        self.f.write(line)
        
    
batch_write_cbk = SaveBatchLevelDataCallback(validation_data=valid_data,save_dir='batch_data')

# add to the callback list
my_callbacks = [time_stopping_callback,early_stopping_callback,checkpoint,batch_write_cbk, CSVLogger('new.csv', separator=',')]

```


```python
# # Compile the model
from keras import metrics
model.compile(loss='categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy',
                        metrics.AUC(name='auc'),
                        metrics.Precision(name='precision'),
                        metrics.Recall(name='recall'),
                        F1_Score])

# Fitting the model with more metrics

num_epochs = 10

history=model.fit(train_data,
                  steps_per_epoch =train_steps_per_epoch, 
                  validation_data=valid_data,
                  epochs=num_epochs,
                  validation_steps=valid_steps_per_epoch,
                  callbacks=my_callbacks)
```


```python
# print history 
print(history.history)
```


```python
#plot accuracy vs epoch
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validate'], loc='upper left')
plt.show()

# Plot loss values vs epoch
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validate'], loc='upper left')
plt.show()

# Plot loss values vs epoch
plt.plot(history.history['F1_Score'])
plt.plot(history.history['val_F1_Score'])
plt.title('Model F1-Score')
plt.ylabel('F1_Score')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validate'], loc='upper left')
plt.show()

# Plot accuracy vs. prevision
plt.plot(history.history['precision'],label='precision')
plt.plot(history.history['val_precision'],label='val_precision')
plt.plot(history.history['recall'],label='recall')
plt.plot(history.history['val_recall'],label='val_precision')
plt.title('Model Precision and Recall')
plt.ylabel('Precision and Recall')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Plot accuracy vs. prevision
plt.plot(history.history['precision'],history.history['recall'],'o', color='black',label='precision vs. recall')
plt.plot(history.history['recall'],history.history['val_recall'],'o', color='red',label='val_precision vs. val_recall')
plt.title('Model Precision and Recall')
plt.ylabel('Precision')
plt.xlabel('Recall')
plt.legend()
plt.show()

# Evaluate against test data.
scores = model.evaluate(test_data, verbose=1)

print('Test loss:', scores[0])
print('Test accuracy:', scores[1])
print('Test AUC:', scores[1])
print('Test precision:', scores[1])
print('Test recall:', scores[1])
print('Test F1-Score:', scores[1])

```


```python
# For evaluation first, we will create the actual and predicted labels
# We can then use these to generate all the reports we need.

# make predictions on the testing images, finding the index of the
# label with the corresponding largest predicted probability

predicted = model.predict(x=test_data, steps=test_steps_per_epoch)

# create predited IDs
predicted = np.argmax(predicted, axis=1)

# create test labels from the generator
actual = []
for i in range(0,int(test_steps_per_epoch)):
    actual.extend(np.array(test_data[i][1]))

# create actual IDs
actual = np.asarray(actual).argmax(axis=1)

# make sure predicted and actual are the same size and shape
print(predicted.shape)
print(actual.shape)
```


```python
from sklearn.metrics import classification_report

print("[INFO] evaluating network...")
print(classification_report(actual, predicted))
```


```python
# Now we can determine the confusion matrix
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(actual,predicted)

def print_cm(cm, frm, to,abs_or_relative=0):
    import seaborn as sns
    import matplotlib.pylab as plt

    cm = cm[frm:to+1,frm:to+1]
    # create labels
    x_axis_labels = np.arange(frm,to+1)
    y_axis_labels = np.arange(frm,to+1)
    
    plt.xticks(rotation=45)
    plt.yticks(rotation=-45)
    
    if(abs_or_relative==0):
        sns.heatmap(cm, annot=True,xticklabels=x_axis_labels, yticklabels=y_axis_labels)
    else:
        sns.heatmap(cm/np.sum(cm), annot=True, 
           fmt='.2%', cmap='Blues',
           xticklabels=x_axis_labels, yticklabels=y_axis_labels)

print_cm(cm,1 ,20,0)
```


```python
# we already have actual and predicted 

# also see https://www.dlology.com/blog/simple-guide-on-how-to-generate-roc-plot-for-keras-classifier/
# for micro-average ROC curves as well

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

fpr = dict()
tpr = dict()
roc_auc = dict()

#extract the actual labels from the test data
Y_test = []
for i in range(0,int(test_steps_per_epoch)):
    Y_test.extend(np.array(test_data[i][1]))
Y_test = np.array(Y_test)
n_classes = Y_test.shape[1]  # one hot encoded

# create actual output from the model using test_data
y_score=model.predict(x=test_data, steps=test_steps_per_epoch)

print(Y_test.shape)
print(y_score.shape)
```


```python
print(n_classes)
# compare each class's probabilities one by one
# each acts like a single column
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(Y_test[:,i], y_score[:,i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Print the AUC scores
from IPython.display import display
import pandas as pd
auc_array = np.array(list(roc_auc.items()))
df = pd.DataFrame(auc_array[:,1])
df.columns = ['AUC']
display(df)
```


```python
# plot the ROC for the ith class cls
import matplotlib.pyplot as plt
import os

def plot_roc(cls,roc_dir):  
    plt.plot(fpr[cls], tpr[cls], lw=2,label='ROC curve of class {0} (area = {1:0.3f})'
    ''.format(cls, roc_auc[cls]))
    plt.plot([0, 1], [0, 1], 'k--', lw=2)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC')
    plt.legend(loc="lower right")
    plt.tight_layout()
    plt.savefig(os.path.join(roc_dir, f'ROC_{cls}.png'))
    plt.show()


# make sure directory exists
def make_directory(roc_dir):
    try:
        os.mkdir(roc_dir)
    except OSError:
        print ("Creation of the directory %s failed" % roc_dir)
    else:
        print ("Successfully created the directory %s " % roc_dir)
        
# print the roc curve for 0

make_directory('rocs')

for i in range(n_classes):
    plot_roc(i,'rocs')
```


```python
# Using tensorflow extension
# Load the TensorBoard notebook extension
%load_ext tensorboard
import datetime
```


```python
# Define tensorboard callback

log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

# Using remote tensorboard
#https://blog.yyliu.net/remote-tensorboard/
```


```python
# Compile the model
from keras import metrics
model.compile(loss='categorical_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy',
                        metrics.AUC(name='auc'),
                        metrics.Precision(name='precision'),
                        metrics.Recall(name='recall')])

# Fitting the model with more metrics

num_epochs = 10

history=model.fit(train_data,
                  steps_per_epoch =train_steps_per_epoch, 
                  validation_data=valid_data,
                  epochs=num_epochs,
                  validation_steps=valid_steps_per_epoch,
                  callbacks=[tensorboard_callback])
```


```python
#%tensorboard --logdir logs/fit
```


```python

```
